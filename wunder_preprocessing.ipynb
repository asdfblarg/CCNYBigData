{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7f7360da0450>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = spark.read.load('wunderground_2011-2013.csv', format='csv', header=True, inferSchema=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TimeEDT', 'string'),\n",
       " ('TemperatureF', 'string'),\n",
       " ('Dew PointF', 'string'),\n",
       " ('Humidity', 'string'),\n",
       " ('Sea Level PressureIn', 'string'),\n",
       " ('VisibilityMPH', 'string'),\n",
       " ('Wind Direction', 'string'),\n",
       " ('Wind SpeedMPH', 'string'),\n",
       " ('Gust SpeedMPH', 'string'),\n",
       " ('PrecipitationIn', 'string'),\n",
       " ('Events', 'string'),\n",
       " ('Conditions', 'string'),\n",
       " ('WindDirDegrees', 'string'),\n",
       " ('DateUTC', 'string')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "import csv\n",
    "from dateutil.parser import parse\n",
    "from dateutil.tz import gettz\n",
    "from dateutil import tz\n",
    "# from datetime import datetime\n",
    "\n",
    "\n",
    "utc = parse(utc_datetime)\n",
    "\n",
    "from_zone = tz.gettz('UTC')\n",
    "to_zone = tz.gettz('America/New_York')\n",
    "\n",
    "\n",
    "def process_wunder(idx, part):\n",
    "    if idx == 0:\n",
    "        part.next()\n",
    "    from_zone = tz.gettz('UTC')\n",
    "    to_zone = tz.gettz('America/New_York')\n",
    "    for p in csv.reader(part):\n",
    "        # deal with edge case of 'No daily or hourly history data available'\n",
    "        # for 1/28/2012, 1/29/2012, 1/30/2012\n",
    "        if len(p) < 12:\n",
    "            continue\n",
    "        freezing = '0'\n",
    "        windy = '0'\n",
    "        fog = '0'\n",
    "        rain = '0'\n",
    "        snow = '0'\n",
    "        if  float(p[1]) <= 32:\n",
    "            freezing = '1'\n",
    "        try: \n",
    "            if float(p[7]) >= 30:\n",
    "                windy = '1'\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            if  0 <= float(p[5]) <= '1' or 'fog' in p[10] :\n",
    "                fog = '1'\n",
    "        except: \n",
    "            pass\n",
    "\n",
    "        if 'Rain' in p[10] or 'Rain' in p[11]:\n",
    "            rain = '1'\n",
    "\n",
    "        if 'Snow' in p[10] or 'Snow' in p[11]:\n",
    "            snow = '1'\n",
    "        \n",
    "        DateUTC = parse(p[13])\n",
    "        DatetimeEDT = DateUTC.replace(tzinfo=from_zone).astimezone(to_zone)\n",
    "        \n",
    "        yield Row(  \n",
    "                    DateUTC = p[13],\n",
    "                    TimeEDT = p[0],\n",
    "                    TemperatureF = p[1],\n",
    "                    Dew_PointF = p[2],\n",
    "                    Humidity = p[3],\n",
    "                    Sea_Level_PressureIn = p[4],\n",
    "                    VisibilityMPH = p[5],\n",
    "                    Wind_Direction = p[6],\n",
    "                    Wind_SpeedMPH = p[7],\n",
    "                    Gust_SpeedMPH = p[8],\n",
    "                    PrecipitationIn = p[9],\n",
    "                    Events = p[10],\n",
    "                    Conditions = p[11],\n",
    "                    WindDirDegrees = p[12],\n",
    "                    Freezing = freezing,\n",
    "                    Windy = windy,\n",
    "                    Foggy = fog,\n",
    "                    Rain = rain,\n",
    "                    Snow = snow,\n",
    "                    DatetimeEDT = DatetimeEDT,\n",
    "                    )\n",
    "        \n",
    "rows = sc.textFile('wunderground_2011-2017_final.csv').mapPartitionsWithIndex(process_wunder)\n",
    "df = sqlContext.createDataFrame(rows)\n",
    "df.toPandas().to_csv('processed_2011-2017_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.dtypes\n",
    "# df.select(\"DateUTC\", \"Snow\", \"Windy\", \"Rain\").toPandas().to_csv('test2.csv')\n",
    "df.select(\"DateUTC\", \"DatetimeEDT\", \"TimeEDT\").toPandas().to_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if temp < 32: freezeing bool true\n",
    "wind speed > 31 mph: windy true\n",
    "0< visibilty < 1 mile: low visiiablity\n",
    "rain: rain \n",
    "snow: snow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.toPandas().to_csv('processed_2011-2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-01-02 06:48:00+00:00\n",
      "2011-01-02 01:48:00-05:00\n"
     ]
    }
   ],
   "source": [
    "from dateutil.parser import parse\n",
    "from dateutil.tz import gettz\n",
    "from datetime import datetime\n",
    "from dateutil import tz\n",
    "\n",
    "utc_datetime = '2011-01-02 06:48:00'\n",
    "edt_datetime = '1:48 AM'\n",
    "edt_datetime = '2011-01-02 1:48:00'\n",
    "\n",
    "utc = parse(utc_datetime)\n",
    "\n",
    "from_zone = tz.gettz('UTC')\n",
    "to_zone = tz.gettz('America/New_York')\n",
    "\n",
    "# Tell the datetime object that it's in UTC time zone since \n",
    "# datetime objects are 'naive' by default\n",
    "utc = utc.replace(tzinfo=from_zone)\n",
    "\n",
    "# # Convert time zone\n",
    "est = utc.astimezone(to_zone)\n",
    "\n",
    "print(utc)\n",
    "print(est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.take(2)\n",
    "unique_Conditions = df.select(\"Conditions\").distinct()\n",
    "unique_Conditions.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|         Conditions|\n",
      "+-------------------+\n",
      "|       Thunderstorm|\n",
      "|Light Freezing Rain|\n",
      "|   Scattered Clouds|\n",
      "|                Fog|\n",
      "|              Clear|\n",
      "|      Partly Cloudy|\n",
      "| Light Freezing Fog|\n",
      "|            Unknown|\n",
      "|      Mostly Cloudy|\n",
      "|         Heavy Rain|\n",
      "|         Light Rain|\n",
      "|               Mist|\n",
      "|               Snow|\n",
      "|               Rain|\n",
      "|               Haze|\n",
      "|           Overcast|\n",
      "|         Light Snow|\n",
      "|         Heavy Snow|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique_Conditions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "+------------+\n",
      "|      Events|\n",
      "+------------+\n",
      "|Thunderstorm|\n",
      "|    Fog-Snow|\n",
      "|         Fog|\n",
      "|    Fog-Rain|\n",
      "|        Rain|\n",
      "|        Snow|\n",
      "|            |\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique_Events = df.select(\"Events\").distinct()\n",
    "print unique_Events.count()\n",
    "unique_Events.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('linkId', 'string'),\n",
       " ('linkPoints', 'string'),\n",
       " ('EncodedPolyLine', 'string'),\n",
       " ('EncodedPolyLineLvls', 'string'),\n",
       " ('Transcom_id', 'string'),\n",
       " ('Borough', 'string'),\n",
       " ('linkName', 'string'),\n",
       " ('Owner', 'string')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkinfo = spark.read.load('linkinfo.csv', format='csv', header=True, inferSchema=False)\n",
    "linkinfo.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Id', 'string'),\n",
       " ('Speed', 'string'),\n",
       " ('TravelTime', 'string'),\n",
       " ('Status', 'string'),\n",
       " ('DataAsOf', 'string'),\n",
       " ('linkId', 'string')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "april2015 = spark.read.load('april2015.csv', format='csv', header=True, inferSchema=False)\n",
    "april2015.dtypes\n",
    "# april2015.rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4616337', ('1', '16.78', '303', '0', '4/18/2015 09:05:34')),\n",
       " ('4616325', ('2', '21.75', '145', '0', '4/18/2015 09:05:34')),\n",
       " ('4616324', ('3', '16.78', '358', '0', '4/18/2015 09:05:34')),\n",
       " ('4616338', ('4', '21.13', '154', '0', '4/18/2015 09:05:34')),\n",
       " ('4616323', ('106', '16.78', '131', '0', '4/18/2015 09:05:34'))]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def map_linkID(idx, part):\n",
    "    if idx == 0:\n",
    "        part.next()\n",
    "    for p in csv.reader(part):\n",
    "        yield (p[5], (p[0], p[1], p[2], p[3], p[4]) )\n",
    "\n",
    "april2015_rdd = sc.textFile('april2015.csv').mapPartitionsWithIndex(map_linkID)\n",
    "april2015_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4616337',\n",
       "  ('40.74047,-74.009251 40.74137,-74.00893 40.7431706,-74.008591 40.7462304,-74.00797 40.74812,-74.007651 40.748701,-74.007691 40.74971,-74.00819 40.75048,-74.008321 40.751611,-74.00789 40.7537504,-74.00704 40.75721,-74.00463 40.76003,-74.002631 40.7607405,-7',\n",
       "   '}btwFx|ubMsD_AgJcAcR{ByJ_AsBFiEbByCXaFuAkLiDsTaNsPoKmCmB',\n",
       "   'BBBBBBBBBBBBB',\n",
       "   '4616337',\n",
       "   'Manhattan',\n",
       "   '11th ave n ganservoort - 12th ave @ 40th st',\n",
       "   7)),\n",
       " ('4616325',\n",
       "  ('40.73933,-74.01004 40.73895,-74.01012 40.7376,-74.010021 40.7346,-74.01026 40.72912,-74.010781 40.72619,-74.011131',\n",
       "   'y{swFvavbMjANlGSvQn@fa@fBhQdA',\n",
       "   'BBBBBB',\n",
       "   '4616325',\n",
       "   'Manhattan',\n",
       "   '11th ave s ganservoort - west st @ spring st',\n",
       "   7))]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_linkinfo_id(idx, part):\n",
    "    if idx == 0:\n",
    "        part.next()\n",
    "    for p in csv.reader(part):\n",
    "        yield (p[0], (p[1], p[2], p[3], p[4], p[5], p[6],7) )\n",
    "\n",
    "linkinfo_rdd = sc.textFile('linkinfo.csv').mapPartitionsWithIndex(map_linkinfo_id)\n",
    "linkinfo_rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4616297',\n",
       "  (('178', '52.2', '162', '0', '4/18/2015 09:05:34'),\n",
       "   ('40.8302204,-73.850641 40.8295305,-73.848401 40.8291004,-73.847491 40.82836,-73.8459 40.8281405,-73.84524 40.8280305,-73.844641 40.827991,-73.843911 40.82804,-73.842981 40.8281906,-73.841761 40.8286304,-73.83844 40.82887,-73.83673 40.8291904,-73.83548 40.8',\n",
       "    '{sexFn}vaMhC_MtAuDrC}Hj@cCTwBFqCIyD]sFwAwSo@uI_AyFe@wBmAmE}A}DwAsCyFqK{DmH}AuD{D_KeCiCiCmAuDQwC`@kH`B',\n",
       "    'BBBBBBBBBBBBBBBBBBBBBBBBB',\n",
       "    '4616297',\n",
       "    'Bronx',\n",
       "    'CBE E CASTLE HILL AVE - BE N WATERBURY AVE',\n",
       "    7))),\n",
       " ('4616297',\n",
       "  (('178', '50.95', '166', '0', '4/18/2015 09:10:34'),\n",
       "   ('40.8302204,-73.850641 40.8295305,-73.848401 40.8291004,-73.847491 40.82836,-73.8459 40.8281405,-73.84524 40.8280305,-73.844641 40.827991,-73.843911 40.82804,-73.842981 40.8281906,-73.841761 40.8286304,-73.83844 40.82887,-73.83673 40.8291904,-73.83548 40.8',\n",
       "    '{sexFn}vaMhC_MtAuDrC}Hj@cCTwBFqCIyD]sFwAwSo@uI_AyFe@wBmAmE}A}DwAsCyFqK{DmH}AuD{D_KeCiCiCmAuDQwC`@kH`B',\n",
       "    'BBBBBBBBBBBBBBBBBBBBBBBBB',\n",
       "    '4616297',\n",
       "    'Bronx',\n",
       "    'CBE E CASTLE HILL AVE - BE N WATERBURY AVE',\n",
       "    7)))]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "april2015_rdd.join(linkinfo_rdd).take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
